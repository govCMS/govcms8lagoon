# Return with a `Disallow: /` for non-production URLs

if ($uri = "/robots.txt"){
  set $robots_disallow_test "isRobotstxtURI";
}

# matches *.govcms.gov.au (multiple subdomains)
# matches *.govcms.amazee.io (multiple subdomains)
#
# Excludes matching on www.govcms.gov.au
if ($host ~* ^(?!www\.govcms\.gov\.au$)(?:[\w\-]+\.)+govcms\.(gov\.au|amazee\.io)$){
  set $robots_disallow_test "$robots_disallow_test+isGovcmsHost";
}

if ($robots_disallow_test = "isRobotstxtURI+isGovcmsHost"){
  return 200 'User-agent: *\nDisallow: /';
}
